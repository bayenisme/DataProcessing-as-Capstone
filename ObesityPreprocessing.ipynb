{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9820b67",
   "metadata": {},
   "source": [
    "# **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6d5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be01569",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (2824301346.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpd.set_option('display.max_columns, None)\u001b[39m\n                  ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns, None)\n",
    "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ObesityDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc305e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"5 Data Pertama\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInformasi Dataset\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a165fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStatistik Deskriptif\")\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f15c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nJumlah Missing Value\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32192a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nJumlah Data Duplikat\")\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ecf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nUnique Value per Kolom\")\n",
    "print(df.nUnique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e781826",
   "metadata": {},
   "source": [
    "# **Visualisasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477a4f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data=df, x='NObeyesdad', order=df['NObeyesdad'].value_counts().index)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Distribusi Kelas Target (NObeyesdad)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "plt.figure(figsize=(15,10))\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d3b77",
   "metadata": {},
   "source": [
    "# **Preprocessing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b8cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "def remove_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    return data[(data[column] >= lower) & (data[column] <= upper)]\n",
    "\n",
    "for col in ['Age', 'Height', 'Weight']:\n",
    "    df = remove_outliers_iqr(df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e60f2",
   "metadata": {},
   "source": [
    "# **Encoding Kategorikal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcbcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_encoded = df.copy()\n",
    "\n",
    "for col in df_encoded.columns:\n",
    "    if df_encoded[col].dtype == 'object':\n",
    "        df_encoded[col] = label_encoder.fit_transform(df_encoded[col])\n",
    "\n",
    "X = df_encoded.drop('NObeyesdad', axis=1)\n",
    "y = df_encoded['NObeyesdad']\n",
    "\n",
    "print(\"\\nDistribusi kelas setelah encoding:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346b9a4",
   "metadata": {},
   "source": [
    "# **Handling Imbalance dan Normalisasi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ae906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inisialisasi model\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Training dan evaluasi\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e573018",
   "metadata": {},
   "source": [
    "## **Visualisasi Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1 Score': []\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_scores['Model'].append(name)\n",
    "    model_scores['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    model_scores['Precision'].append(precision_score(y_test, y_pred, average='weighted'))\n",
    "    model_scores['Recall'].append(recall_score(y_test, y_pred, average='weighted'))\n",
    "    model_scores['F1 Score'].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "score_df = pd.DataFrame(model_scores)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "score_df_melted = score_df.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
    "sns.barplot(data=score_df_melted, x='Model', y='Score', hue='Metric')\n",
    "plt.title('Perbandingan Performa Model')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd646d",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=3, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Best Parameters - Random Forest:\")\n",
    "print(grid_rf.best_params_)\n",
    "print(\"\\nClassification Report (Tuned Random Forest):\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0391bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1: Manhattan, 2: Euclidean\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=3, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "best_knn = grid_knn.best_estimator_\n",
    "y_pred_knn = best_knn.predict(X_test)\n",
    "\n",
    "print(\"Best Parameters - KNN:\")\n",
    "print(grid_knn.best_params_)\n",
    "print(\"\\nClassification Report (Tuned KNN):\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c38dded",
   "metadata": {},
   "source": [
    "## **Visualisasi Hasil Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdba0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'F1 Score': f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "\n",
    "comparison_scores = {\n",
    "    'Model': [],\n",
    "    'Stage': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1 Score': []\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    metrics = get_metrics(model, X_test, y_test)\n",
    "    comparison_scores['Model'].append(name)\n",
    "    comparison_scores['Stage'].append('Before Tuning')\n",
    "    comparison_scores['Accuracy'].append(metrics['Accuracy'])\n",
    "    comparison_scores['Precision'].append(metrics['Precision'])\n",
    "    comparison_scores['Recall'].append(metrics['Recall'])\n",
    "    comparison_scores['F1 Score'].append(metrics['F1 Score'])\n",
    "\n",
    "tuned_models = {\n",
    "    'Random Forest': best_rf,\n",
    "    'KNN': best_knn\n",
    "}\n",
    "\n",
    "for name, model in tuned_models.items():\n",
    "    metrics = get_metrics(model, X_test, y_test)\n",
    "    comparison_scores['Model'].append(name)\n",
    "    comparison_scores['Stage'].append('After Tuning')\n",
    "    comparison_scores['Accuracy'].append(metrics['Accuracy'])\n",
    "    comparison_scores['Precision'].append(metrics['Precision'])\n",
    "    comparison_scores['Recall'].append(metrics['Recall'])\n",
    "    comparison_scores['F1 Score'].append(metrics['F1 Score'])\n",
    "\n",
    "score_compare_df = pd.DataFrame(comparison_scores)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "score_melted = score_compare_df.melt(id_vars=['Model', 'Stage'], var_name='Metric', value_name='Score')\n",
    "\n",
    "sns.barplot(data=score_melted, x='Model', y='Score', hue='Stage', palette='Set2', ci=None)\n",
    "plt.title('Perbandingan Performa Sebelum vs Sesudah Tuning')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Skor (0-1)')\n",
    "plt.legend(title='Stage')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20d836a",
   "metadata": {},
   "source": [
    "1. Dataset yang digunakan memiliki 2111 data dengan 17 fitur dan 1 target yang merepresentasikan tingkat obesitas pada individu dari Meksiko, Peru, dan Kolombia\n",
    "2. Dataset memiliki distribusi kelas target yang tidak seimbang dan terdapat outlier pada kolom Weight, Height, dan Age\n",
    "3. Algoritma Random Forest dan KNN mendapatkan performa yang lebih tinggi dibanding Logistic Regression\n",
    "4. Hyperparameter Tuning dibutuhkan agar performa model dapat ditingkatkan, khususnya pada Random Forest dan KNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
